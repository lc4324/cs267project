{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6H6dSslDUwjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea17dc9-e78f-4074-8c3f-6f4d1400608f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBZNiCatZQOt",
        "outputId": "645e24a4-92f7-4239-fd3d-13e094e658d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdHjj4E9eZIj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#from transformers import Trainer\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datetime import datetime\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchmetrics import F1Score\n",
        "\n",
        "# import datasets\n",
        "# from datasets import Dataset, load_metric\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "puGaYCZhirtE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9YLKELHeZIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac2f682-fd9c-4e35-d822-ee9567d67ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "album_favorites        Int64\n",
            "album_title         category\n",
            "artist_favorites       Int64\n",
            "artist_name         category\n",
            "track_favorites        Int64\n",
            "track_genre_top     category\n",
            "track_genres          object\n",
            "track_genres_all      object\n",
            "track_interest         Int64\n",
            "track_listens          Int64\n",
            "track_title           object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "dt = {'album_favorites': 'Int64', 'album_title': 'category', \n",
        " 'artist_favorites': 'Int64', 'artist_name': 'category', 'track_favorites':'Int64', 'track_genre_top': 'category',\n",
        " 'track_genres': 'object', 'track_genres_all':'object', 'track_interest':'Int64', 'track_listens': 'Int64',\n",
        " 'track_title': 'object' }\n",
        "csv_path = '/content/drive/My Drive/cs267a/data.csv'\n",
        "all_data = pd.read_csv(csv_path, dtype= dt)\n",
        "\n",
        "print(all_data.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4SC9gQ5eZIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12686469-8851-4b3a-d6dd-23513b57f2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 9783\n"
          ]
        }
      ],
      "source": [
        "# all_data = all_data.drop(all_data[all_data['track_title'].isna()].index)\n",
        "# all_data = all_data.drop(all_data[all_data['artist_name'].isna()].index)\n",
        "all_data = all_data.drop(all_data[all_data['album_title'].isna()].index)\n",
        "all_data = all_data.drop(all_data[all_data['artist_favorites'] == -1].index)\n",
        "all_data = all_data.drop(all_data[all_data['album_favorites'] == -1].index)\n",
        "print(f\"dataset size: {len(all_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fLqBM9TeZIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7dfe68c-9da5-4cdb-a7c3-dc4bf7f34476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 9783\n"
          ]
        }
      ],
      "source": [
        "#data_frame = all_data[:2000]\n",
        "data_frame = all_data\n",
        "print(f\"dataset size: {len(data_frame)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYBdRBWveZIt"
      },
      "outputs": [],
      "source": [
        "def get_level(q75, q50, q25, val): \n",
        "    if val > q75: return 3\n",
        "    if val > q50: return 2\n",
        "    if val > q25: return 1\n",
        "    return 0\n",
        "\n",
        "def convert_to_level(data_frame):\n",
        "  #split the numerical value into 4 levels.\n",
        "  album_fav_q75 = data_frame['album_favorites'].quantile(0.75)\n",
        "  album_fav_q50 = data_frame['album_favorites'].quantile(0.50)\n",
        "  album_fav_q25 = data_frame['album_favorites'].quantile(0.25)\n",
        "  data_frame['album_favorites_level'] = data_frame.apply(lambda row: get_level(album_fav_q75,album_fav_q50,album_fav_q25, row['album_favorites']), axis = 1)\n",
        "\n",
        "  artist_fav_q75 = data_frame['artist_favorites'].quantile(0.75)\n",
        "  artist_fav_q50 = data_frame['artist_favorites'].quantile(0.50)\n",
        "  artist_fav_q25 = data_frame['artist_favorites'].quantile(0.25)\n",
        "  data_frame['artist_favorites_level'] = data_frame.apply(lambda row: get_level(artist_fav_q75,artist_fav_q50,artist_fav_q25, row['artist_favorites']), axis = 1)\n",
        "\n",
        "  track_int_q75 = data_frame['track_interest'].quantile(0.75)\n",
        "  track_int_q50 = data_frame['track_interest'].quantile(0.50)\n",
        "  track_int_q25 = data_frame['track_interest'].quantile(0.25)\n",
        "  data_frame['track_interest_level'] = data_frame.apply(lambda row: get_level(track_int_q75,track_int_q50,track_int_q25, row['track_interest']), axis = 1)\n",
        "\n",
        "  track_lis_q75 = data_frame['track_listens'].quantile(0.75)\n",
        "  track_lis_q50 = data_frame['track_listens'].quantile(0.50)\n",
        "  track_lis_q25 = data_frame['track_listens'].quantile(0.25)\n",
        "  data_frame['track_listens_level'] = data_frame.apply(lambda row: get_level(track_lis_q75,track_lis_q50,track_lis_q25, row['track_listens']), axis = 1)\n",
        "\n",
        "\n",
        "  track_fav_q75 = data_frame['track_favorites'].quantile(0.75)\n",
        "  track_fav_q50 = data_frame['track_favorites'].quantile(0.50)\n",
        "  track_fav_q25 = data_frame['track_favorites'].quantile(0.25)\n",
        "  data_frame['track_favorites_level'] = data_frame.apply(lambda row: get_level(track_fav_q75,track_fav_q50,track_fav_q25, row['track_favorites']), axis = 1)\n",
        "\n",
        "\n",
        "  #normalziation \n",
        "  #data_frame['album_favorites_level'] = MinMaxScaler().fit_transform(np.array(data_frame['album_favorites_level']).reshape(-1,1))\n",
        "  #data_frame['artist_favorites_level'] = MinMaxScaler().fit_transform(np.array(data_frame['artist_favorites_level']).reshape(-1,1))\n",
        "  #data_frame['track_interest_level'] = MinMaxScaler().fit_transform(np.array(data_frame['track_interest_level']).reshape(-1,1))\n",
        "  #data_frame['track_listens_level'] = MinMaxScaler().fit_transform(np.array(data_frame['track_listens_level']).reshape(-1,1))\n",
        "  #data_frame['track_favorites_level'] = MinMaxScaler().fit_transform(np.array(data_frame['track_favorites_level']).reshape(-1,1))\n",
        "  return data_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGbTa2GeeZIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835c6942-9100-4635-daaa-fdc318abf306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       album_favorites           album_title  artist_favorites artist_name  \\\n",
            "0                    4  AWOL - A Way Of Life                 9        AWOL   \n",
            "1                    4  AWOL - A Way Of Life                 9        AWOL   \n",
            "2                    4  AWOL - A Way Of Life                 9        AWOL   \n",
            "3                    4     Constant Hitmaker                74   Kurt Vile   \n",
            "4                    2                 Niris                10  Nicky Cook   \n",
            "...                ...                   ...               ...         ...   \n",
            "10082                2                   Eve                10     Shearer   \n",
            "10083                2                   Eve                10     Shearer   \n",
            "10084                2                   Eve                10     Shearer   \n",
            "10085                2                   Eve                10     Shearer   \n",
            "10086                2                   Eve                10     Shearer   \n",
            "\n",
            "       track_favorites track_genre_top   track_genres   track_genres_all  \\\n",
            "0                    2         Hip-Hop           [21]               [21]   \n",
            "1                    1         Hip-Hop           [21]               [21]   \n",
            "2                    6         Hip-Hop           [21]               [21]   \n",
            "3                  178             Pop           [10]               [10]   \n",
            "4                    0             NaN      [76, 103]  [17, 10, 76, 103]   \n",
            "...                ...             ...            ...                ...   \n",
            "10082                2            Rock  [12, 45, 111]  [25, 12, 45, 111]   \n",
            "10083                1            Rock  [12, 45, 111]  [25, 12, 45, 111]   \n",
            "10084                2            Rock  [12, 45, 111]  [25, 12, 45, 111]   \n",
            "10085                1            Rock  [12, 45, 111]  [25, 12, 45, 111]   \n",
            "10086                1            Rock  [12, 45, 111]  [25, 12, 45, 111]   \n",
            "\n",
            "       track_interest  track_listens        track_title  \\\n",
            "0                4656           1293               Food   \n",
            "1                1470            514       Electric Ave   \n",
            "2                1933           1151         This World   \n",
            "3               54881          50135            Freeway   \n",
            "4                 978            361    Spiritual Level   \n",
            "...               ...            ...                ...   \n",
            "10082            1381            538      Bring Me Down   \n",
            "10083            1458            644      Can't Stop It   \n",
            "10084            1391            636      Ordinary Girl   \n",
            "10085            1393            676                 69   \n",
            "10086            1278            524  Consequence of Da   \n",
            "\n",
            "       album_favorites_level  artist_favorites_level  track_interest_level  \\\n",
            "0                          3                       2                     3   \n",
            "1                          3                       2                     2   \n",
            "2                          3                       2                     2   \n",
            "3                          3                       3                     3   \n",
            "4                          2                       2                     1   \n",
            "...                      ...                     ...                   ...   \n",
            "10082                      2                       2                     2   \n",
            "10083                      2                       2                     2   \n",
            "10084                      2                       2                     2   \n",
            "10085                      2                       2                     2   \n",
            "10086                      2                       2                     2   \n",
            "\n",
            "       track_listens_level  track_favorites_level  \n",
            "0                        3                      2  \n",
            "1                        2                      1  \n",
            "2                        3                      3  \n",
            "3                        3                      3  \n",
            "4                        1                      0  \n",
            "...                    ...                    ...  \n",
            "10082                    2                      2  \n",
            "10083                    2                      1  \n",
            "10084                    2                      2  \n",
            "10085                    2                      1  \n",
            "10086                    2                      1  \n",
            "\n",
            "[9783 rows x 16 columns]\n"
          ]
        }
      ],
      "source": [
        "convert_to_level(data_frame)\n",
        "print(data_frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_average(d):\n",
        "  for k in d:\n",
        "    d[k] = sum(d[k])/len(d[k])\n",
        "  return d"
      ],
      "metadata": {
        "id": "NyicFvxspCIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "albums = {}\n",
        "artists = {}\n",
        "genres = {}\n",
        "sond_id = 0\n",
        "\n",
        "for index, row in data_frame.iterrows():\n",
        "    # define albums\n",
        "    album = str(row['album_title'])\n",
        "    if not album in albums:\n",
        "        albums[album] = [row['track_favorites_level']]\n",
        "    else:\n",
        "        albums[album].append(row['track_favorites_level'])\n",
        "    # define artists\n",
        "    artist = str(row['artist_name'])\n",
        "    if not artist in artists:\n",
        "        artists[artist] = [row['track_favorites_level']]\n",
        "    else:\n",
        "        artists[artist].append(row['track_favorites_level'])\n",
        "    # define genres\n",
        "    genre = str(row['track_genre_top'])\n",
        "    if not genre in genres:\n",
        "        genres[genre] = [row['track_favorites_level']]\n",
        "    else:\n",
        "        genres[genre].append(row['track_favorites_level'])\n",
        "    sond_id+=1\n",
        "\n",
        "\n",
        "dataset_size = sond_id\n",
        "print(\"sond_id:\", sond_id)\n",
        "print(\"max index: \", index)\n",
        "print(\"len(data_frame): \", len(data_frame))\n",
        "albums = get_average(albums)\n",
        "artists = get_average(artists)\n",
        "genres = get_average(genres)\n",
        "\n",
        "data_x = torch.zeros([dataset_size, 3])\n",
        "data_y = torch.zeros([dataset_size], dtype=torch.int64)\n",
        "\n",
        "song_id = 0\n",
        "level = torch.zeros([4])\n",
        "for index, row in data_frame.iterrows():\n",
        "    data_x[song_id, 0] = albums[str(row['album_title'])]\n",
        "    data_x[song_id, 1] = artists[str(row['artist_name'])]\n",
        "    data_x[song_id, 2] = genres[str(row['track_genre_top'])]\n",
        "    data_y[song_id] = row['track_favorites_level']\n",
        "    level[row['track_favorites_level']] += 1\n",
        "    song_id+=1\n",
        "\n",
        "print(level)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4np8g1gkKa0",
        "outputId": "ee971950-440c-4b56-86c8-22beaad4f66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sond_id: 9783\n",
            "max index:  10086\n",
            "len(data_frame):  9783\n",
            "tensor([3866., 2192., 2004., 1721.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle(data_x, data_y):\n",
        "  r=torch.randperm(data_x.shape[0])\n",
        "  return data_x[r], data_y[r]"
      ],
      "metadata": {
        "id": "226UWoN63MZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_x, data_y = shuffle(data_x, data_y)\n",
        "train_size = int(0.8*data_x.shape[0])\n",
        "train_x = data_x[:train_size]\n",
        "train_y = data_y[:train_size]\n",
        "test_x = data_x[train_size:]\n",
        "test_y = data_y[train_size:]"
      ],
      "metadata": {
        "id": "kDWqHITF3N5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "T1VgLjiokITg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(3, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        return F.softmax(out)\n",
        "\n",
        "class LinearClassifier2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier2, self).__init__()\n",
        "        self.layer1 = nn.Linear(3, 4)\n",
        "        self.layer2 = nn.Linear(4,4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.layer1(x))\n",
        "        out = self.layer2(out)\n",
        "\n",
        "        return F.softmax(out)"
      ],
      "metadata": {
        "id": "Xbyero5-f5iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, batch_size, data_x, data_y):\n",
        "  model.eval()\n",
        "  f1_micro = F1Score(num_classes=4)\n",
        "  f1_macro = F1Score(num_classes=4, average='macro')\n",
        "  X = data_x\n",
        "  y = data_y\n",
        "  output = model(X)\n",
        "  _, pred = torch.max(output, 1)\n",
        "  num_correct = np.count_nonzero(pred.eq(y.data.view_as(pred)))\n",
        "  num_samples = y.size(dim=0)\n",
        "\n",
        "  accuracy = num_correct / num_samples\n",
        "  return accuracy, f1_micro(pred, y), f1_macro(pred, y)\n",
        "\n",
        "def train(model, lr, momentum, num_epochs, batch_size, data_x, data_y, test_x, test_y, displayinfo=True):\n",
        "  opt = optim.SGD(model.parameters(), lr=lr,\n",
        "                      momentum=momentum)\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  dataset_size = data_x.shape[0]\n",
        "\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for i in range(dataset_size//batch_size+1):\n",
        "      start = i*batch_size\n",
        "      end = min(start+batch_size, dataset_size)\n",
        "      X = data_x[start:end]\n",
        "      y = data_y[start:end]\n",
        "      opt.zero_grad()\n",
        "      output = model(X)\n",
        "      loss = criterion(output,y)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      train_loss += loss.item() * X.size(0)\n",
        "      _, pred = torch.max(output, 1)\n",
        "      num_correct += np.count_nonzero(pred.eq(y.data.view_as(pred)))\n",
        "      num_samples += y.size(dim=0)\n",
        "\n",
        "    train_accuracy = num_correct/num_samples\n",
        "    test_accuracy, f1score_micro, f1score_macro = test(model, batch_size, test_x, test_y)\n",
        "    if displayinfo:\n",
        "      print(\"loss at epoch \", epoch, \" : \", train_loss)\n",
        "      print(\"Training accuracy at epoch \", epoch, \" : \", train_accuracy)\n",
        "      print(f\"Test accuracy at epoch {epoch}: {test_accuracy:.4f}\")\n",
        "      print(f\"Test f1score_micro at epoch {epoch}: {f1score_micro:.4f}\")\n",
        "      print(f\"Test f1score_macro at epoch {epoch}: {f1score_macro:.4f}\")\n",
        "    if epoch == num_epochs:\n",
        "      return train_accuracy, test_accuracy, f1score_micro, f1score_macro"
      ],
      "metadata": {
        "id": "sqQF0yeRhkki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "lr = 0.5\n",
        "momentum = 0.9\n",
        "batch_size = 256\n",
        "\n",
        "model = LinearClassifier()\n",
        "train_accuracy, test_accuracy, f1score_micro, f1score_macro = train(model, lr, momentum, num_epochs, batch_size, train_x, train_y, test_x, test_y)\n",
        "\n",
        "print(f\"train_accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"test_accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"f1score_micro: {f1score_micro:.4f}\")\n",
        "print(f\"f1score_macro: {f1score_macro:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCPZAvOlsPO4",
        "outputId": "2ca7f4d9-e733-4a1f-8087-01125f012bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at epoch  1  :  9739.823960781097\n",
            "Training accuracy at epoch  1  :  0.4723996933299259\n",
            "Test accuracy at epoch 1: 0.6045\n",
            "Test f1score_micro at epoch 1: 0.6045\n",
            "Test f1score_macro at epoch 1: 0.4784\n",
            "loss at epoch  2  :  8905.532413959503\n",
            "Training accuracy at epoch  2  :  0.6056733963710708\n",
            "Test accuracy at epoch 2: 0.6157\n",
            "Test f1score_micro at epoch 2: 0.6157\n",
            "Test f1score_macro at epoch 2: 0.4930\n",
            "loss at epoch  3  :  8813.194992542267\n",
            "Training accuracy at epoch  3  :  0.6242013800153335\n",
            "Test accuracy at epoch 3: 0.6306\n",
            "Test f1score_micro at epoch 3: 0.6306\n",
            "Test f1score_macro at epoch 3: 0.5129\n",
            "loss at epoch  4  :  8743.307918787003\n",
            "Training accuracy at epoch  4  :  0.6337848198313315\n",
            "Test accuracy at epoch 4: 0.6290\n",
            "Test f1score_micro at epoch 4: 0.6290\n",
            "Test f1score_macro at epoch 4: 0.5112\n",
            "loss at epoch  5  :  8625.826308012009\n",
            "Training accuracy at epoch  5  :  0.6340403782264248\n",
            "Test accuracy at epoch 5: 0.6239\n",
            "Test f1score_micro at epoch 5: 0.6239\n",
            "Test f1score_macro at epoch 5: 0.5112\n",
            "loss at epoch  6  :  8555.374132871628\n",
            "Training accuracy at epoch  6  :  0.6501405571173013\n",
            "Test accuracy at epoch 6: 0.6290\n",
            "Test f1score_micro at epoch 6: 0.6290\n",
            "Test f1score_macro at epoch 6: 0.5213\n",
            "loss at epoch  7  :  8508.249577522278\n",
            "Training accuracy at epoch  7  :  0.6625351392793253\n",
            "Test accuracy at epoch 7: 0.6438\n",
            "Test f1score_micro at epoch 7: 0.6438\n",
            "Test f1score_macro at epoch 7: 0.5655\n",
            "loss at epoch  8  :  8472.623965740204\n",
            "Training accuracy at epoch  8  :  0.6689240991566573\n",
            "Test accuracy at epoch 8: 0.6612\n",
            "Test f1score_micro at epoch 8: 0.6612\n",
            "Test f1score_macro at epoch 8: 0.6051\n",
            "loss at epoch  9  :  8444.387574195862\n",
            "Training accuracy at epoch  9  :  0.6758241758241759\n",
            "Test accuracy at epoch 9: 0.6633\n",
            "Test f1score_micro at epoch 9: 0.6633\n",
            "Test f1score_macro at epoch 9: 0.6099\n",
            "loss at epoch  10  :  8421.161968231201\n",
            "Training accuracy at epoch  10  :  0.6795297725530284\n",
            "Test accuracy at epoch 10: 0.6658\n",
            "Test f1score_micro at epoch 10: 0.6658\n",
            "Test f1score_macro at epoch 10: 0.6142\n",
            "loss at epoch  11  :  8401.64554643631\n",
            "Training accuracy at epoch  11  :  0.6808075645284948\n",
            "Test accuracy at epoch 11: 0.6689\n",
            "Test f1score_micro at epoch 11: 0.6689\n",
            "Test f1score_macro at epoch 11: 0.6196\n",
            "loss at epoch  12  :  8384.902869939804\n",
            "Training accuracy at epoch  12  :  0.682852031689241\n",
            "Test accuracy at epoch 12: 0.6735\n",
            "Test f1score_micro at epoch 12: 0.6735\n",
            "Test f1score_macro at epoch 12: 0.6291\n",
            "loss at epoch  13  :  8370.32082438469\n",
            "Training accuracy at epoch  13  :  0.6820853565039612\n",
            "Test accuracy at epoch 13: 0.6745\n",
            "Test f1score_micro at epoch 13: 0.6745\n",
            "Test f1score_macro at epoch 13: 0.6311\n",
            "loss at epoch  14  :  8357.469053030014\n",
            "Training accuracy at epoch  14  :  0.6820853565039612\n",
            "Test accuracy at epoch 14: 0.6781\n",
            "Test f1score_micro at epoch 14: 0.6781\n",
            "Test f1score_macro at epoch 14: 0.6362\n",
            "loss at epoch  15  :  8346.028429031372\n",
            "Training accuracy at epoch  15  :  0.6841298236647074\n",
            "Test accuracy at epoch 15: 0.6791\n",
            "Test f1score_micro at epoch 15: 0.6791\n",
            "Test f1score_macro at epoch 15: 0.6377\n",
            "loss at epoch  16  :  8335.75469660759\n",
            "Training accuracy at epoch  16  :  0.6847687196524406\n",
            "Test accuracy at epoch 16: 0.6786\n",
            "Test f1score_micro at epoch 16: 0.6786\n",
            "Test f1score_macro at epoch 16: 0.6376\n",
            "loss at epoch  17  :  8326.457008600235\n",
            "Training accuracy at epoch  17  :  0.6863020700230003\n",
            "Test accuracy at epoch 17: 0.6796\n",
            "Test f1score_micro at epoch 17: 0.6796\n",
            "Test f1score_macro at epoch 17: 0.6393\n",
            "loss at epoch  18  :  8317.982864618301\n",
            "Training accuracy at epoch  18  :  0.6868131868131868\n",
            "Test accuracy at epoch 18: 0.6817\n",
            "Test f1score_micro at epoch 18: 0.6817\n",
            "Test f1score_macro at epoch 18: 0.6428\n",
            "loss at epoch  19  :  8310.210734128952\n",
            "Training accuracy at epoch  19  :  0.68745208280092\n",
            "Test accuracy at epoch 19: 0.6827\n",
            "Test f1score_micro at epoch 19: 0.6827\n",
            "Test f1score_macro at epoch 19: 0.6445\n",
            "loss at epoch  20  :  8303.04089307785\n",
            "Training accuracy at epoch  20  :  0.6884743163812931\n",
            "Test accuracy at epoch 20: 0.6842\n",
            "Test f1score_micro at epoch 20: 0.6842\n",
            "Test f1score_macro at epoch 20: 0.6470\n",
            "loss at epoch  21  :  8296.392624616623\n",
            "Training accuracy at epoch  21  :  0.6893687707641196\n",
            "Test accuracy at epoch 21: 0.6847\n",
            "Test f1score_micro at epoch 21: 0.6847\n",
            "Test f1score_macro at epoch 21: 0.6480\n",
            "loss at epoch  22  :  8290.200234889984\n",
            "Training accuracy at epoch  22  :  0.6887298747763864\n",
            "Test accuracy at epoch 22: 0.6863\n",
            "Test f1score_micro at epoch 22: 0.6863\n",
            "Test f1score_macro at epoch 22: 0.6499\n",
            "loss at epoch  23  :  8284.40926861763\n",
            "Training accuracy at epoch  23  :  0.6886020955788398\n",
            "Test accuracy at epoch 23: 0.6873\n",
            "Test f1score_micro at epoch 23: 0.6873\n",
            "Test f1score_macro at epoch 23: 0.6509\n",
            "loss at epoch  24  :  8278.976165056229\n",
            "Training accuracy at epoch  24  :  0.6889854331714796\n",
            "Test accuracy at epoch 24: 0.6888\n",
            "Test f1score_micro at epoch 24: 0.6888\n",
            "Test f1score_macro at epoch 24: 0.6527\n",
            "loss at epoch  25  :  8273.864739656448\n",
            "Training accuracy at epoch  25  :  0.6898798875543062\n",
            "Test accuracy at epoch 25: 0.6903\n",
            "Test f1score_micro at epoch 25: 0.6903\n",
            "Test f1score_macro at epoch 25: 0.6553\n",
            "loss at epoch  26  :  8269.044976472855\n",
            "Training accuracy at epoch  26  :  0.6911576795297726\n",
            "Test accuracy at epoch 26: 0.6924\n",
            "Test f1score_micro at epoch 26: 0.6924\n",
            "Test f1score_macro at epoch 26: 0.6591\n",
            "loss at epoch  27  :  8264.492038726807\n",
            "Training accuracy at epoch  27  :  0.6915410171224124\n",
            "Test accuracy at epoch 27: 0.6919\n",
            "Test f1score_micro at epoch 27: 0.6919\n",
            "Test f1score_macro at epoch 27: 0.6588\n",
            "loss at epoch  28  :  8260.184913158417\n",
            "Training accuracy at epoch  28  :  0.6914132379248659\n",
            "Test accuracy at epoch 28: 0.6919\n",
            "Test f1score_micro at epoch 28: 0.6919\n",
            "Test f1score_macro at epoch 28: 0.6588\n",
            "loss at epoch  29  :  8256.106148004532\n",
            "Training accuracy at epoch  29  :  0.6915410171224124\n",
            "Test accuracy at epoch 29: 0.6924\n",
            "Test f1score_micro at epoch 29: 0.6924\n",
            "Test f1score_macro at epoch 29: 0.6597\n",
            "loss at epoch  30  :  8252.239603996277\n",
            "Training accuracy at epoch  30  :  0.6923076923076923\n",
            "Test accuracy at epoch 30: 0.6934\n",
            "Test f1score_micro at epoch 30: 0.6934\n",
            "Test f1score_macro at epoch 30: 0.6613\n",
            "train_accuracy: 0.6923\n",
            "test_accuracy: 0.6934\n",
            "f1score_micro: 0.6934\n",
            "f1score_macro: 0.6613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "lr_list = [0.001, 0.01, 0.1, 0.2, 0.5, 1, 5]\n",
        "momentum_list = [0, 0.1, 0.2, 0.5, 0.8, 0.9, 1]\n",
        "batch_size = 256\n",
        "\n",
        "train_accuracies = torch.zeros([len(lr_list), len(momentum_list)])\n",
        "test_accuracies = torch.zeros([len(lr_list), len(momentum_list)])\n",
        "test_f1score_micro = torch.zeros([len(lr_list), len(momentum_list)])\n",
        "test_f1score_macro = torch.zeros([len(lr_list), len(momentum_list)])\n",
        "\n",
        "for i in range(len(lr_list)):\n",
        "  lr = lr_list[i]\n",
        "  for j in range(len(momentum_list)):\n",
        "    momentum = momentum_list[j]\n",
        "    model = LinearClassifier()\n",
        "    train_accuracy, test_accuracy, f1score_micro, f1score_macro = train(model, lr, momentum, num_epochs, batch_size, train_x, train_y, test_x, test_y, displayinfo=False)\n",
        "    train_accuracies[i,j] = train_accuracy\n",
        "    test_accuracies[i,j] = test_accuracy\n",
        "    test_f1score_micro[i,j] = f1score_micro\n",
        "    test_f1score_macro[i,j] = f1score_macro\n",
        "    print(f\"lr: {lr}, momentum: {momentum}, train_accuracy: {train_accuracy:.4f}, test_accuracy: {test_accuracy:.4f}, f1score_micro: {f1score_micro:.4f}, f1score_macro: {f1score_macro:.4f}\")\n",
        "\n",
        "print(\"train_accuracies: \", train_accuracies)\n",
        "print(\"test_accuracies: \", test_accuracies)\n",
        "print(\"test_f1score_micro: \", test_f1score_micro)\n",
        "print(\"test_f1score_macro: \", test_f1score_macro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpqGFCYjJ0dT",
        "outputId": "ea48ba6f-8884-4611-951b-821ad5ca50bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr: 0.001, momentum: 0, train_accuracy: 0.2296, test_accuracy: 0.2264, f1score_micro: 0.2264, f1score_macro: 0.1022\n",
            "lr: 0.001, momentum: 0.1, train_accuracy: 0.5891, test_accuracy: 0.5846, f1score_micro: 0.5846, f1score_macro: 0.4616\n",
            "lr: 0.001, momentum: 0.2, train_accuracy: 0.1797, test_accuracy: 0.1620, f1score_micro: 0.1620, f1score_macro: 0.0697\n",
            "lr: 0.001, momentum: 0.5, train_accuracy: 0.2029, test_accuracy: 0.1998, f1score_micro: 0.1998, f1score_macro: 0.1126\n",
            "lr: 0.001, momentum: 0.8, train_accuracy: 0.5098, test_accuracy: 0.5294, f1score_micro: 0.5294, f1score_macro: 0.3164\n",
            "lr: 0.001, momentum: 0.9, train_accuracy: 0.5382, test_accuracy: 0.5539, f1score_micro: 0.5539, f1score_macro: 0.3295\n",
            "lr: 0.001, momentum: 1, train_accuracy: 0.5521, test_accuracy: 0.5432, f1score_micro: 0.5432, f1score_macro: 0.3299\n",
            "lr: 0.01, momentum: 0, train_accuracy: 0.5210, test_accuracy: 0.5156, f1score_micro: 0.5156, f1score_macro: 0.3206\n",
            "lr: 0.01, momentum: 0.1, train_accuracy: 0.5488, test_accuracy: 0.5416, f1score_micro: 0.5416, f1score_macro: 0.3296\n",
            "lr: 0.01, momentum: 0.2, train_accuracy: 0.5542, test_accuracy: 0.5432, f1score_micro: 0.5432, f1score_macro: 0.3307\n",
            "lr: 0.01, momentum: 0.5, train_accuracy: 0.5530, test_accuracy: 0.5437, f1score_micro: 0.5437, f1score_macro: 0.3305\n",
            "lr: 0.01, momentum: 0.8, train_accuracy: 0.5534, test_accuracy: 0.5452, f1score_micro: 0.5452, f1score_macro: 0.3319\n",
            "lr: 0.01, momentum: 0.9, train_accuracy: 0.5553, test_accuracy: 0.5457, f1score_micro: 0.5457, f1score_macro: 0.3370\n",
            "lr: 0.01, momentum: 1, train_accuracy: 0.6894, test_accuracy: 0.6888, f1score_micro: 0.6888, f1score_macro: 0.6503\n",
            "lr: 0.1, momentum: 0, train_accuracy: 0.5560, test_accuracy: 0.5468, f1score_micro: 0.5468, f1score_macro: 0.3374\n",
            "lr: 0.1, momentum: 0.1, train_accuracy: 0.5679, test_accuracy: 0.5544, f1score_micro: 0.5544, f1score_macro: 0.3640\n",
            "lr: 0.1, momentum: 0.2, train_accuracy: 0.5633, test_accuracy: 0.5529, f1score_micro: 0.5529, f1score_macro: 0.3640\n",
            "lr: 0.1, momentum: 0.5, train_accuracy: 0.5905, test_accuracy: 0.5800, f1score_micro: 0.5800, f1score_macro: 0.4360\n",
            "lr: 0.1, momentum: 0.8, train_accuracy: 0.5805, test_accuracy: 0.6030, f1score_micro: 0.6030, f1score_macro: 0.4516\n",
            "lr: 0.1, momentum: 0.9, train_accuracy: 0.6767, test_accuracy: 0.6699, f1score_micro: 0.6699, f1score_macro: 0.6181\n",
            "lr: 0.1, momentum: 1, train_accuracy: 0.5446, test_accuracy: 0.5554, f1score_micro: 0.5554, f1score_macro: 0.3335\n",
            "lr: 0.2, momentum: 0, train_accuracy: 0.5956, test_accuracy: 0.5912, f1score_micro: 0.5912, f1score_macro: 0.4615\n",
            "lr: 0.2, momentum: 0.1, train_accuracy: 0.6026, test_accuracy: 0.5948, f1score_micro: 0.5948, f1score_macro: 0.4736\n",
            "lr: 0.2, momentum: 0.2, train_accuracy: 0.6072, test_accuracy: 0.5953, f1score_micro: 0.5953, f1score_macro: 0.4806\n",
            "lr: 0.2, momentum: 0.5, train_accuracy: 0.6314, test_accuracy: 0.6208, f1score_micro: 0.6208, f1score_macro: 0.5313\n",
            "lr: 0.2, momentum: 0.8, train_accuracy: 0.5915, test_accuracy: 0.6081, f1score_micro: 0.6081, f1score_macro: 0.4624\n",
            "lr: 0.2, momentum: 0.9, train_accuracy: 0.6891, test_accuracy: 0.6832, f1score_micro: 0.6832, f1score_macro: 0.6429\n",
            "lr: 0.2, momentum: 1, train_accuracy: 0.6918, test_accuracy: 0.6878, f1score_micro: 0.6878, f1score_macro: 0.6532\n",
            "lr: 0.5, momentum: 0, train_accuracy: 0.6417, test_accuracy: 0.6275, f1score_micro: 0.6275, f1score_macro: 0.5394\n",
            "lr: 0.5, momentum: 0.1, train_accuracy: 0.6504, test_accuracy: 0.6341, f1score_micro: 0.6341, f1score_macro: 0.5495\n",
            "lr: 0.5, momentum: 0.2, train_accuracy: 0.6593, test_accuracy: 0.6408, f1score_micro: 0.6408, f1score_macro: 0.5630\n",
            "lr: 0.5, momentum: 0.5, train_accuracy: 0.6779, test_accuracy: 0.6730, f1score_micro: 0.6730, f1score_macro: 0.6221\n",
            "lr: 0.5, momentum: 0.8, train_accuracy: 0.6905, test_accuracy: 0.6842, f1score_micro: 0.6842, f1score_macro: 0.6473\n",
            "lr: 0.5, momentum: 0.9, train_accuracy: 0.6923, test_accuracy: 0.6924, f1score_micro: 0.6924, f1score_macro: 0.6599\n",
            "lr: 0.5, momentum: 1, train_accuracy: 0.6431, test_accuracy: 0.6403, f1score_micro: 0.6403, f1score_macro: 0.5255\n",
            "lr: 1, momentum: 0, train_accuracy: 0.6745, test_accuracy: 0.6730, f1score_micro: 0.6730, f1score_macro: 0.6223\n",
            "lr: 1, momentum: 0.1, train_accuracy: 0.5916, test_accuracy: 0.6091, f1score_micro: 0.6091, f1score_macro: 0.4633\n",
            "lr: 1, momentum: 0.2, train_accuracy: 0.6825, test_accuracy: 0.6781, f1score_micro: 0.6781, f1score_macro: 0.6321\n",
            "lr: 1, momentum: 0.5, train_accuracy: 0.6885, test_accuracy: 0.6863, f1score_micro: 0.6863, f1score_macro: 0.6495\n",
            "lr: 1, momentum: 0.8, train_accuracy: 0.5934, test_accuracy: 0.6060, f1score_micro: 0.6060, f1score_macro: 0.4631\n",
            "lr: 1, momentum: 0.9, train_accuracy: 0.6965, test_accuracy: 0.6960, f1score_micro: 0.6960, f1score_macro: 0.6688\n",
            "lr: 1, momentum: 1, train_accuracy: 0.6369, test_accuracy: 0.6285, f1score_micro: 0.6285, f1score_macro: 0.4978\n",
            "lr: 5, momentum: 0, train_accuracy: 0.6921, test_accuracy: 0.6709, f1score_micro: 0.6709, f1score_macro: 0.6202\n",
            "lr: 5, momentum: 0.1, train_accuracy: 0.6926, test_accuracy: 0.6709, f1score_micro: 0.6709, f1score_macro: 0.6215\n",
            "lr: 5, momentum: 0.2, train_accuracy: 0.6935, test_accuracy: 0.6832, f1score_micro: 0.6832, f1score_macro: 0.6431\n",
            "lr: 5, momentum: 0.5, train_accuracy: 0.6981, test_accuracy: 0.7026, f1score_micro: 0.7026, f1score_macro: 0.6736\n",
            "lr: 5, momentum: 0.8, train_accuracy: 0.4900, test_accuracy: 0.5089, f1score_micro: 0.5089, f1score_macro: 0.3064\n",
            "lr: 5, momentum: 0.9, train_accuracy: 0.5450, test_accuracy: 0.5565, f1score_micro: 0.5565, f1score_macro: 0.3320\n",
            "lr: 5, momentum: 1, train_accuracy: 0.5920, test_accuracy: 0.6152, f1score_micro: 0.6152, f1score_macro: 0.4740\n",
            "train_accuracies:  tensor([[0.2296, 0.5891, 0.1797, 0.2029, 0.5098, 0.5382, 0.5521],\n",
            "        [0.5210, 0.5488, 0.5542, 0.5530, 0.5534, 0.5553, 0.6894],\n",
            "        [0.5560, 0.5679, 0.5633, 0.5905, 0.5805, 0.6767, 0.5446],\n",
            "        [0.5956, 0.6026, 0.6072, 0.6314, 0.5915, 0.6891, 0.6918],\n",
            "        [0.6417, 0.6504, 0.6593, 0.6779, 0.6905, 0.6923, 0.6431],\n",
            "        [0.6745, 0.5916, 0.6825, 0.6885, 0.5934, 0.6965, 0.6369],\n",
            "        [0.6921, 0.6926, 0.6935, 0.6981, 0.4900, 0.5450, 0.5920]])\n",
            "test_accuracies:  tensor([[0.2264, 0.5846, 0.1620, 0.1998, 0.5294, 0.5539, 0.5432],\n",
            "        [0.5156, 0.5416, 0.5432, 0.5437, 0.5452, 0.5457, 0.6888],\n",
            "        [0.5468, 0.5544, 0.5529, 0.5800, 0.6030, 0.6699, 0.5554],\n",
            "        [0.5912, 0.5948, 0.5953, 0.6208, 0.6081, 0.6832, 0.6878],\n",
            "        [0.6275, 0.6341, 0.6408, 0.6730, 0.6842, 0.6924, 0.6403],\n",
            "        [0.6730, 0.6091, 0.6781, 0.6863, 0.6060, 0.6960, 0.6285],\n",
            "        [0.6709, 0.6709, 0.6832, 0.7026, 0.5089, 0.5565, 0.6152]])\n",
            "test_f1score_micro:  tensor([[0.2264, 0.5846, 0.1620, 0.1998, 0.5294, 0.5539, 0.5432],\n",
            "        [0.5156, 0.5416, 0.5432, 0.5437, 0.5452, 0.5457, 0.6888],\n",
            "        [0.5468, 0.5544, 0.5529, 0.5800, 0.6030, 0.6699, 0.5554],\n",
            "        [0.5912, 0.5948, 0.5953, 0.6208, 0.6081, 0.6832, 0.6878],\n",
            "        [0.6275, 0.6341, 0.6408, 0.6730, 0.6842, 0.6924, 0.6403],\n",
            "        [0.6730, 0.6091, 0.6781, 0.6863, 0.6060, 0.6960, 0.6285],\n",
            "        [0.6709, 0.6709, 0.6832, 0.7026, 0.5089, 0.5565, 0.6152]])\n",
            "test_f1score_macro:  tensor([[0.1022, 0.4616, 0.0697, 0.1126, 0.3164, 0.3295, 0.3299],\n",
            "        [0.3206, 0.3296, 0.3307, 0.3305, 0.3319, 0.3370, 0.6503],\n",
            "        [0.3374, 0.3640, 0.3640, 0.4360, 0.4516, 0.6181, 0.3335],\n",
            "        [0.4615, 0.4736, 0.4806, 0.5313, 0.4624, 0.6429, 0.6532],\n",
            "        [0.5394, 0.5495, 0.5630, 0.6221, 0.6473, 0.6599, 0.5255],\n",
            "        [0.6223, 0.4633, 0.6321, 0.6495, 0.4631, 0.6688, 0.4978],\n",
            "        [0.6202, 0.6215, 0.6431, 0.6736, 0.3064, 0.3320, 0.4740]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "2311630a52cedeaec8888e3ac2f1a57854d2acf548d26364ef7186e17f759282"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('ml_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}